# Glossary of Terms

This glossary defines key terms used throughout the Physical AI & Humanoid Robotics book.

## A

**Actuator**: A component of a robot that converts energy (often electrical) into physical motion. Common actuators include motors, pneumatic cylinders, and hydraulic systems.

**AI Safety**: The field of study focused on ensuring artificial intelligence systems operate safely and reliably, particularly in human environments.

**Anthropomorphism**: The attribution of human characteristics or behaviors to non-human entities, such as robots.

## B

**Balance Control**: Systems and algorithms that allow a humanoid robot to maintain its center of mass within its support polygon to avoid falling.

**Behavior Tree**: A hierarchical structure used for organizing tasks and actions in robotics and AI, representing a sequence of decisions and actions.

## C

**Computer Vision**: A field of artificial intelligence that trains computers to interpret and understand the visual world, using digital images and machine learning models.

**Control Theory**: The interdisciplinary branch of engineering and mathematics dealing with the behavior of dynamical systems with inputs, and how their behavior is modified by feedback.

**Cognitive Robotics**: A branch of robotics that aims to create robots with human-like cognitive capabilities, including perception, reasoning, and learning.

## D

**Deep Reinforcement Learning**: A type of machine learning that combines deep learning with reinforcement learning, allowing agents to learn optimal behaviors through interaction with an environment.

**Degrees of Freedom (DOF)**: The number of independent movements a mechanical system can make, typically referring to the number of joints or independent actuators in a robot.

**Dynamics**: The study of forces and torques and their effect on motion, particularly the motion of mechanical systems.

## E

**Embodied AI**: A field of artificial intelligence research that emphasizes the role of a physical body in intelligent behavior, arguing that intelligence emerges from the interaction between an agent and its environment.

**End Effector**: The tool or device attached to the end of a robot arm, such as a gripper or welding torch, that interacts with the environment.

**Ethical AI**: The development of artificial intelligence systems that align with human values, rights, and ethical principles.

## F

**Forward Kinematics**: The process of determining the position and orientation of a robot's end effector based on the joint angles of the robot.

**Force Control**: A robotic control strategy that regulates the forces applied by a robot to its environment, often used in tasks requiring physical interaction.

## G

**Gait**: The pattern of movement of the limbs in locomotion, particularly important in humanoid robotics for walking.

**Gaussian Process**: A non-parametric machine learning method used for regression and classification that can model uncertainty in predictions.

## H

**Human-Robot Interaction (HRI)**: The study of interactions between humans and robots, encompassing design, development, and evaluation of robots for human use.

**Humanoid Robot**: A robot with a body structure similar to that of a human, typically featuring a head, torso, two arms, and two legs.

**Hybrid Systems**: Systems that exhibit both continuous and discrete dynamic behavior, common in robotic applications.

## I

**Impedance Control**: A control strategy that regulates the dynamic relationship between position and force, allowing robots to respond appropriately to environmental contacts.

**Inverse Kinematics**: The mathematical process of determining the joint angles required to position a robot's end effector at a specific location and orientation.

**Intention Recognition**: The ability of a robot to infer human intentions from observed behavior, speech, or other cues.

## J

**Joint Space**: The space defined by the range of motion of a robot's joints, as opposed to Cartesian space.

## K

**Kinematics**: The study of motion without considering the forces that cause the motion, particularly the motion of mechanical systems.

## L

**Legged Locomotion**: The act of moving from place to place using legs, a challenging problem in robotics requiring complex control systems.

**Learning from Demonstration (LfD)**: A technique in robotics where a robot learns tasks by observing human demonstrations.

## M

**Machine Learning**: A branch of artificial intelligence that enables systems to learn and improve from experience without being explicitly programmed.

**Manipulation**: The ability of a robot to physically handle and move objects in its environment.

**Monte Carlo Methods**: A class of computational algorithms that rely on random sampling to obtain numerical results, often used in robotics and AI planning.

## N

**Natural Language Processing (NLP)**: A field of artificial intelligence focused on enabling computers to understand, interpret, and generate human language.

**Neural Networks**: Computing systems inspired by the human brain that learn to perform tasks by considering examples, generally without task-specific programming.

## P

**Path Planning**: The computational problem of finding a valid sequence of configurations to move an object from an initial configuration to a goal configuration.

**Perception**: The process by which robots interpret sensory information to understand and navigate their environment.

**Proxemics**: The study of personal space and the distances individuals maintain during social interactions, important for robot navigation in human environments.

**Policy Gradient**: A class of reinforcement learning algorithms that directly optimize the policy parameters to maximize expected reward.

## R

**Reinforcement Learning**: A type of machine learning where agents learn to make decisions by taking actions in an environment to maximize some notion of cumulative reward.

**Robot Operating System (ROS)**: A flexible framework for writing robot software that provides hardware abstraction, device drivers, libraries, and more.

**ROS 2**: The second generation of the Robot Operating System, designed to be more robust, secure, and suitable for production applications.

**Rapid Prototyping**: The quick construction of a working model for a proposed system, particularly important in robotics development.

## S

**Sensor Fusion**: The process of combining sensory data from multiple sources to achieve more accurate and reliable information than could be obtained from a single sensor.

**Social Robotics**: The study of robots designed to interact with humans in a socially acceptable manner.

**State Estimation**: The process of determining the state of a system from noisy or incomplete measurements, often using techniques like Kalman filtering.

**Stereoscopic Vision**: A technique for creating depth perception using two cameras to simulate human binocular vision.

## T

**Trajectory Planning**: The process of determining the path and timing for a robot to move from one configuration to another.

**Teleoperation**: The remote operation of a robot by a human operator, often used for tasks in dangerous or inaccessible environments.

**Telerobotics**: The area of robotics focused on remote operation of robots, often involving haptic feedback and real-time control.

## V

**Visual Servoing**: The technique of controlling a robot using visual feedback, typically from cameras, to guide its actions.

## W

**Whole-Body Control**: Advanced control techniques for humanoid robots that simultaneously consider all joints and tasks to achieve overall motion objectives.

**Wheeled Locomotion**: Movement using wheels, an alternative to legged locomotion in mobile robotics.

## Z

**Zero Moment Point (ZMP)**: A concept used in robotics and biomechanics to propose a stability criterion for legged robots, representing the point where the total moment of the ground reaction forces equals zero.